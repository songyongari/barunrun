{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Autoencoder 기반 이상 탐지 (LSTM/Transformer 등)   \n",
    "1. 기본 개념   \n",
    "정상(전문가) 데이터만으로 Autoencoder를 학습합니다.   \n",
    "모델이 시퀀스(예: 30프레임 × 관절 24개)를 입력받아, 동일한 형태(30×24)를 복원하도록 학습합니다.   \n",
    "정상 패턴을 충분히 학습한 후, 비정상 패턴이 들어오면 복원 오차가 커지게 됩니다.   \n",
    "오차(예: MSE)가 특정 Threshold를 초과하면 “이상치”로 판단할 수 있습니다.   \n",
    "\n",
    "2. 장점   \n",
    "정상 데이터만 있으면 학습 가능하므로, 비정상 데이터가 적어도 어느 정도 동작합니다.   \n",
    "시계열 특성을 반영해 LSTM Autoencoder나 Transformer Autoencoder를 사용하면, 러닝 동작의 연속적 특징을 잘 포착할 수 있습니다.   \n",
    "\n",
    "3. 단점 / 고려사항   \n",
    "데이터가 지속적으로 추가될 때, Autoencoder를 점진적으로 학습(Incremental Learning) 하는 것은 쉽지 않습니다.   \n",
    "보통은 새로운 데이터(정상·비정상)를 모아서 주기적으로 재학습(fine-tuning)하거나, 전량 학습을 다시 하는 식으로 운영합니다.   \n",
    "\n",
    "\n",
    "### 2. 지도학습(이진 분류) 모델 (딥러닝)\n",
    "1. 기본 개념\n",
    "정상과 비정상 모두 충분한 데이터를 확보하면, 이진 분류 모델을 직접 학습시킬 수 있습니다.   \n",
    "시퀀스(30×24) 입력 → LSTM/GRU/Transformer 기반 네트워크 → “정상(1) vs 비정상(0)” 확률 출력   \n",
    "비정상 데이터가 늘어날수록, 모델이 더 정확히 “나쁜 자세”를 인식할 수 있습니다.   \n",
    "\n",
    "2. 장점   \n",
    "정상/비정상 데이터가 충분하면, Autoencoder보다 직관적으로 “어떤 자세가 나쁜지”를 배울 수 있습니다.   \n",
    "비정상 패턴이 다양해질수록 모델이 더 견고해집니다.   \n",
    "\n",
    "3. 단점 / 고려사항   \n",
    "비정상 데이터가 많아야 제대로 학습할 수 있습니다.   \n",
    "추가 학습(Incremental Learning)을 구현하려면, 기존 모델에 새 데이터를 미니배치로 넣어 재학습하거나, 주기적으로 전량 학습을 다시 해야 합니다.   \n",
    "\n",
    "\n",
    "### 3. 장기적인 모델 업데이트 전략\n",
    "1. 데이터 저장 & 주기적 재학습   \n",
    "새로운 사용자 데이터를 지속적으로 수집(정상·비정상 레이블)   \n",
    "일정 주기(예: 한 달, 분기)마다 모델을 전량 재학습하거나, 파인튜닝하여 성능 개선   \n",
    "딥러닝 프레임워크(TensorFlow/PyTorch)로 구현 가능   \n",
    "\n",
    "2. 온라인 학습(Online/Incremental Learning)   \n",
    "일부 알고리즘(예: 일부 계열의 Neural Network, 일부 scikit-learn 모델)은 부분 학습(Partial Fit)을 지원   \n",
    "하지만 시계열 딥러닝 모델(LSTM, Transformer 등)은 아직 안정적인 온라인 학습 구현이 쉽지 않습니다.   \n",
    "보통은 주기적 미니배치 재학습 형태가 현실적입니다.   \n",
    "\n",
    "3. 데이터 품질 관리   \n",
    "비정상 자세가 다양해질수록 모델이 학습해야 할 패턴이 늘어납니다.   \n",
    "라벨링(“이 시퀀스는 나쁜 자세”) 품질이 높아야 모델도 안정적으로 성능을 높일 수 있습니다.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "\n",
    "def build_lstm_autoencoder(timesteps, n_features, latent_dim=64):\n",
    "    \"\"\"\n",
    "    LSTM Autoencoder를 구성하여 반환하는 함수.\n",
    "    timesteps: 시퀀스 길이 (예: 30)\n",
    "    n_features: 프레임당 피처 수 (예: 132 또는 관절 선택 후 24 등)\n",
    "    latent_dim: 인코더의 LSTM 유닛 수 (자유롭게 조정 가능)\n",
    "    \"\"\"\n",
    "    # 인코더\n",
    "    inputs = Input(shape=(timesteps, n_features))\n",
    "    encoded = LSTM(latent_dim)(inputs)\n",
    "    \n",
    "    # RepeatVector: 인코더 출력(1개 타임스텝)을 디코더 입력(timesteps개 타임스텝)으로 확장\n",
    "    encoded = RepeatVector(timesteps)(encoded)\n",
    "    \n",
    "    # 디코더\n",
    "    decoded = LSTM(latent_dim, return_sequences=True)(encoded)\n",
    "    # 각 타임스텝마다 n_features를 출력해야 하므로 TimeDistributed(Dense(n_features))\n",
    "    outputs = TimeDistributed(Dense(n_features))(decoded)\n",
    "    \n",
    "    autoencoder = Model(inputs, outputs)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_csv_and_make_sequences(csv_path, seq_length=30):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # 'frame' 열 제외 -> 33개 랜드마크 × 4개 값 = 132개 열\n",
    "    data = df.iloc[:, 1:].values  # shape: (프레임 수, 132)\n",
    "    n_frames = data.shape[0]\n",
    "\n",
    "    sequences = []\n",
    "    for i in range(n_frames - seq_length + 1):\n",
    "        seq = data[i:i+seq_length]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "# (선택) 특정 관절만 추리는 예시 (원한다면 사용):\n",
    "def select_important_joints(frame_1d):\n",
    "    \"\"\"\n",
    "    필요한 관절 인덱스만 추출.\n",
    "    frame_1d.shape = (132,)\n",
    "    \"\"\"\n",
    "    # 예: 왼엉덩이(23), 오른엉덩이(24), 왼무릎(25), 오른무릎(26), 왼발목(27), 오른발목(28)\n",
    "    # important_landmarks = [23, 24, 25, 26, 27, 28]\n",
    "    # ...\n",
    "    return frame_1d  # 여기서는 전체 사용 (필요시 수정)\n",
    "\n",
    "def load_csv_and_make_sequences_selected(csv_path, seq_length=30):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.dropna()\n",
    "\n",
    "    data = df.iloc[:, 1:].values  # (프레임 수, 132)\n",
    "    n_frames = data.shape[0]\n",
    "\n",
    "    sequences = []\n",
    "    for i in range(n_frames - seq_length + 1):\n",
    "        seq = data[i:i+seq_length]\n",
    "        # 관절 선택\n",
    "        seq_selected = np.array([select_important_joints(frame) for frame in seq])\n",
    "        sequences.append(seq_selected)\n",
    "    return np.array(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_expert shape: (545, 30, 132)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,580</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m132\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m132\u001b[0m)        │         \u001b[38;5;34m8,580\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,036</span> (359.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m92,036\u001b[0m (359.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,036</span> (359.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m92,036\u001b[0m (359.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.1670 - val_loss: 0.0116\n",
      "Epoch 2/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 3/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 4/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 5/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 6/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 7/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 8/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 9/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 10/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 11/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 12/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 13/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 14/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 15/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 16/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 17/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 18/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 19/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 20/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 0.0045\n"
     ]
    }
   ],
   "source": [
    "# 1) CSV 데이터 로드\n",
    "csv_path = r\"C:\\barunrun\\pose_data\\pose_data1.csv\"  # 실제 경로/파일명으로 변경\n",
    "X_expert = load_csv_and_make_sequences(csv_path, seq_length=30)\n",
    "\n",
    "print(\"X_expert shape:\", X_expert.shape)  # 예: (545, 30, 132)\n",
    "\n",
    "# 2) LSTM Autoencoder 모델 생성\n",
    "timesteps = 30\n",
    "n_features = X_expert.shape[2]  # 예: 132 (또는 관절 선택 시 24 등)\n",
    "latent_dim = 64  # 임의 설정 가능\n",
    "\n",
    "autoencoder = build_lstm_autoencoder(timesteps, n_features, latent_dim)\n",
    "autoencoder.summary()\n",
    "\n",
    "# 3) 모델 학습\n",
    "# Autoencoder는 \"입력=X_expert, 출력=X_expert\" 형태로 학습\n",
    "history = autoencoder.fit(\n",
    "    X_expert, X_expert,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_abnormal shape: (381, 30, 132)\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "비정상 데이터 중 이상치로 판단된 시퀀스: 381/381\n",
      "비정상 판단 비율: 1.000\n",
      "임계값: 0.00634, 평균 MSE(전문가): 0.00312, 표준편차: 0.00107\n"
     ]
    }
   ],
   "source": [
    "# 비정상 CSV 로드\n",
    "csv_path_abnormal = r\"C:\\barunrun\\pose_data\\pose_data_abnormal1.csv\"\n",
    "X_abnormal = load_csv_and_make_sequences(csv_path_abnormal, seq_length=30)\n",
    "print(\"X_abnormal shape:\", X_abnormal.shape)\n",
    "\n",
    "# 복원\n",
    "X_abnormal_pred = autoencoder.predict(X_abnormal)\n",
    "\n",
    "# MSE 계산\n",
    "mse_abnormal = np.mean((X_abnormal - X_abnormal_pred)**2, axis=(1,2))\n",
    "\n",
    "# 임계값 설정 (전문가 데이터로 계산)\n",
    "X_expert_pred = autoencoder.predict(X_expert)\n",
    "mse_expert = np.mean((X_expert - X_expert_pred)**2, axis=(1,2))\n",
    "mean_mse_expert = np.mean(mse_expert)\n",
    "std_mse_expert = np.std(mse_expert)\n",
    "threshold = mean_mse_expert + 3*std_mse_expert  # 예시\n",
    "\n",
    "# 비정상 중 이상치로 판단되는 개수\n",
    "abnormal_detected = np.sum(mse_abnormal > threshold)\n",
    "abnormal_ratio = abnormal_detected / len(mse_abnormal)\n",
    "print(f\"비정상 데이터 중 이상치로 판단된 시퀀스: {abnormal_detected}/{len(mse_abnormal)}\")\n",
    "print(f\"비정상 판단 비율: {abnormal_ratio:.3f}\")\n",
    "print(f\"임계값: {threshold:.5f}, 평균 MSE(전문가): {mean_mse_expert:.5f}, 표준편차: {std_mse_expert:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_abnormal shape: (381, 30, 132)\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "비정상 데이터 MSE: [0.08844079 0.08927128 0.09007889 0.09065552 0.09124724 0.09181806\n",
      " 0.09251252 0.09290484 0.09311747 0.09347493]\n",
      "비정상 데이터 중 이상치로 판단된 시퀀스: 381/381\n",
      "비정상 판단 비율: 1.000\n",
      "임계값: 0.00634, 평균 MSE(전문가): 0.00312, 표준편차: 0.00107\n"
     ]
    }
   ],
   "source": [
    "csv_path_abnormal = r\"C:\\barunrun\\pose_data\\pose_data_abnormal1.csv\"\n",
    "X_abnormal = load_csv_and_make_sequences(csv_path_abnormal, seq_length=30)\n",
    "print(\"X_abnormal shape:\", X_abnormal.shape)\n",
    "\n",
    "# Autoencoder로 복원\n",
    "X_abnormal_pred = autoencoder.predict(X_abnormal)\n",
    "\n",
    "# 복원 오차(MSE) 계산\n",
    "mse_abnormal = np.mean((X_abnormal - X_abnormal_pred)**2, axis=(1,2))\n",
    "print(\"비정상 데이터 MSE:\", mse_abnormal[:10])  # 앞 10개 예시 출력\n",
    "\n",
    "# 임계값 설정 (전문가 데이터에서 계산했던 mean_mse_expert, std_mse_expert가 있다고 가정)\n",
    "threshold = mean_mse_expert + 3*std_mse_expert\n",
    "abnormal_detected = np.sum(mse_abnormal > threshold)\n",
    "abnormal_ratio = abnormal_detected / len(mse_abnormal)\n",
    "\n",
    "print(f\"비정상 데이터 중 이상치로 판단된 시퀀스: {abnormal_detected}/{len(mse_abnormal)}\")\n",
    "print(f\"비정상 판단 비율: {abnormal_ratio:.3f}\")\n",
    "print(f\"임계값: {threshold:.5f}, 평균 MSE(전문가): {mean_mse_expert:.5f}, 표준편차: {std_mse_expert:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 비정상 데이터 로드 완료: C:\\barunrun\\pose_data\\pose_data_abnormal1.csv\n",
      "X_abnormal shape: (381, 30, 132)\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "[INFO] 비정상 데이터 MSE (처음 10개): [0.08844079 0.08927128 0.09007889 0.09065552 0.09124724 0.09181806\n",
      " 0.09251252 0.09290484 0.09311747 0.09347493]\n",
      "\n",
      "===== 비정상 데이터 예측 결과 =====\n",
      "총 381개 시퀀스 중, 임계값 초과(이상치): 381\n",
      "비정상 판단 비율: 1.000\n",
      "임계값: 0.00634\n",
      "전문가 데이터 평균 MSE: 0.00312, 표준편차: 0.00107\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# (1) 비정상 CSV 로드\n",
    "##############################\n",
    "csv_path_abnormal = r\"C:\\barunrun\\pose_data\\pose_data_abnormal1.csv\"\n",
    "X_abnormal = load_csv_and_make_sequences(csv_path_abnormal, seq_length=30)\n",
    "print(f\"[INFO] 비정상 데이터 로드 완료: {csv_path_abnormal}\")\n",
    "print(\"X_abnormal shape:\", X_abnormal.shape)\n",
    "\n",
    "##############################\n",
    "# (2) Autoencoder 예측\n",
    "##############################\n",
    "X_abnormal_pred = autoencoder.predict(X_abnormal)\n",
    "\n",
    "##############################\n",
    "# (3) 복원 오차(MSE) 계산\n",
    "##############################\n",
    "mse_abnormal = np.mean((X_abnormal - X_abnormal_pred)**2, axis=(1,2))\n",
    "print(f\"[INFO] 비정상 데이터 MSE (처음 10개): {mse_abnormal[:10]}\")\n",
    "\n",
    "##############################\n",
    "# (4) 임계값 설정\n",
    "##############################\n",
    "# 이미 전문가(정상) 데이터로부터 계산된 mean_mse_expert, std_mse_expert가 있다고 가정\n",
    "# 예) mean_mse_expert = np.mean(mse_expert)\n",
    "#     std_mse_expert = np.std(mse_expert)\n",
    "\n",
    "threshold = mean_mse_expert + 3 * std_mse_expert  # 예시로 평균+3*표준편차 사용\n",
    "\n",
    "##############################\n",
    "# (5) 비정상 시퀀스 중 이상치 판단\n",
    "##############################\n",
    "abnormal_detected = np.sum(mse_abnormal > threshold)\n",
    "abnormal_ratio = abnormal_detected / len(mse_abnormal)\n",
    "\n",
    "##############################\n",
    "# (6) 결과 출력\n",
    "##############################\n",
    "print(\"\\n===== 비정상 데이터 예측 결과 =====\")\n",
    "print(f\"총 {len(mse_abnormal)}개 시퀀스 중, 임계값 초과(이상치): {abnormal_detected}\")\n",
    "print(f\"비정상 판단 비율: {abnormal_ratio:.3f}\")\n",
    "print(f\"임계값: {threshold:.5f}\")\n",
    "print(f\"전문가 데이터 평균 MSE: {mean_mse_expert:.5f}, 표준편차: {std_mse_expert:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barunrun_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
